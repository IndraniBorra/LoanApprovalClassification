{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XsPttS9DAVls"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jEyzikBFBVfW"
   },
   "outputs": [],
   "source": [
    "# Load the wine dataset\n",
    "#data = load_wine()\n",
    "data = pd.read_csv('loan_data.csv')\n",
    "#data = pd.read_csv('loan_data.csv', delimiter=',', na_values=['NA', 'NULL'])\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "# df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "# df['target'] = data.target\n",
    "\n",
    "\n",
    "df = data.copy() # Create a copy to avoid modifying the original DataFrame\n",
    "df.rename(columns={'loan_status': 'target'}, inplace=True)  # Rename the target column\n",
    "feature_names = [col for col in df.columns if col != 'target']\n",
    "\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df[feature_names].values\n",
    "y = df['target'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "D-7GFX4AoHfh",
    "outputId": "06b0e654-4f76-4e0f-f44d-f30b89b74c5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_gender</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>previous_loan_defaults_on_file</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Master</td>\n",
       "      <td>71948.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>16.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>561</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High School</td>\n",
       "      <td>12282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OWN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>504</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High School</td>\n",
       "      <td>12438.0</td>\n",
       "      <td>3</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>12.87</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>635</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>79753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>675</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Master</td>\n",
       "      <td>66135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>14.27</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>586</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age person_gender person_education  person_income  person_emp_exp  \\\n",
       "0        22.0        female           Master        71948.0               0   \n",
       "1        21.0        female      High School        12282.0               0   \n",
       "2        25.0        female      High School        12438.0               3   \n",
       "3        23.0        female         Bachelor        79753.0               0   \n",
       "4        24.0          male           Master        66135.0               1   \n",
       "\n",
       "  person_home_ownership  loan_amnt loan_intent  loan_int_rate  \\\n",
       "0                  RENT    35000.0    PERSONAL          16.02   \n",
       "1                   OWN     1000.0   EDUCATION          11.14   \n",
       "2              MORTGAGE     5500.0     MEDICAL          12.87   \n",
       "3                  RENT    35000.0     MEDICAL          15.23   \n",
       "4                  RENT    35000.0     MEDICAL          14.27   \n",
       "\n",
       "   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n",
       "0                 0.49                         3.0           561   \n",
       "1                 0.08                         2.0           504   \n",
       "2                 0.44                         3.0           635   \n",
       "3                 0.44                         2.0           675   \n",
       "4                 0.53                         4.0           586   \n",
       "\n",
       "  previous_loan_defaults_on_file  target  \n",
       "0                             No       1  \n",
       "1                            Yes       0  \n",
       "2                             No       1  \n",
       "3                             No       1  \n",
       "4                             No       1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "4Ja_MWtWBUd6"
   },
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "def conditional_entropy(y, y_left, y_right):\n",
    "    p_left = len(y_left) / len(y)\n",
    "    p_right = len(y_right) / len(y)\n",
    "    return p_left * entropy(y_left) + p_right * entropy(y_right)\n",
    "\n",
    "def gini(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "def gini_split(y, y_left, y_right):\n",
    "    p_left = len(y_left) / len(y)\n",
    "    p_right = len(y_right) / len(y)\n",
    "    return p_left * gini(y_left) + p_right * gini(y_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eFVx9XTrB8T9"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, criterion='entropy', min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.criterion = criterion\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.tree = None\n",
    "        self.feature_names = None\n",
    "\n",
    "    def fit(self, X, y,feature_names=None):\n",
    "        self.feature_names = data.feature_names\n",
    "        self.tree = self._build_tree(X, y, 0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if len(np.unique(y)) == 1 or (self.max_depth and depth >= self.max_depth) or len(y) < self.min_samples_leaf:\n",
    "            return np.argmax(np.bincount(y))\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if not best_split:\n",
    "            return np.argmax(np.bincount(y))\n",
    "\n",
    "        left_indices, right_indices = best_split['indices']\n",
    "        left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return {'feature': best_split['feature'], 'threshold': best_split['threshold'], 'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        # Define print_tree function locally\n",
    "        def print_tree(node, depth=0):\n",
    "            if isinstance(node, dict):\n",
    "                feature_name = self.feature_names[node['feature']] if self.feature_names else node['feature']\n",
    "                print(\"  \" * depth + f\"[{feature_name} <= {node['threshold']}]\")\n",
    "                print_tree(node['left'], depth + 1)\n",
    "                print_tree(node['right'], depth + 1)\n",
    "            else:\n",
    "                print(\"  \" * depth + f\"[Class: {node}]\")\n",
    "        # Call the local print_tree function to print the actual tree\n",
    "        if node is None:\n",
    "            node = self.tree\n",
    "        print_tree(node, depth)\n",
    "\n",
    "\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        if self.criterion == 'gini':\n",
    "            return self._best_split_gini(X, y)\n",
    "        elif self.criterion == 'entropy':\n",
    "            return self._best_split_entropy(X, y)\n",
    "        else:\n",
    "            raise ValueError(\"Criterion not recognized.\")\n",
    "\n",
    "    def _best_split_gini(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_split = None\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature] > threshold)[0]\n",
    "\n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "\n",
    "                gini = self._gini_index(y[left_indices], y[right_indices])\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_split = {'feature': feature, 'threshold': threshold, 'indices': (left_indices, right_indices)}\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def _gini_index(self, left_y, right_y):\n",
    "        total = len(left_y) + len(right_y)\n",
    "        if total == 0:\n",
    "            return 0\n",
    "\n",
    "        p_left = len(left_y) / total\n",
    "        p_right = len(right_y) / total\n",
    "\n",
    "        gini_left = 1 - sum((np.bincount(left_y) / len(left_y)) ** 2) if len(left_y) > 0 else 0\n",
    "        gini_right = 1 - sum((np.bincount(right_y) / len(right_y)) ** 2) if len(right_y) > 0 else 0\n",
    "\n",
    "        return p_left * gini_left + p_right * gini_right\n",
    "\n",
    "    def _best_split_entropy(self, X, y):\n",
    "        best_entropy = float('inf')\n",
    "        best_split = None\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature] > threshold)[0]\n",
    "\n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "\n",
    "                entropy = self._entropy_index(y[left_indices], y[right_indices])\n",
    "\n",
    "                if entropy < best_entropy:\n",
    "                    best_entropy = entropy\n",
    "                    best_split = {'feature': feature, 'threshold': threshold, 'indices': (left_indices, right_indices)}\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def _entropy_index(self, left_y, right_y):\n",
    "        total = len(left_y) + len(right_y)\n",
    "        if total == 0:\n",
    "            return 0\n",
    "\n",
    "        p_left = len(left_y) / total\n",
    "        p_right = len(right_y) / total\n",
    "\n",
    "        entropy_left = -sum((np.bincount(left_y) / len(left_y)) * np.log2(np.bincount(left_y) / len(left_y) + 1e-9)) if len(left_y) > 0 else 0\n",
    "        entropy_right = -sum((np.bincount(right_y) / len(right_y)) * np.log2(np.bincount(right_y) / len(right_y) + 1e-9)) if len(right_y) > 0 else 0\n",
    "\n",
    "        return p_left * entropy_left + p_right * entropy_right\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_sample(sample, self.tree) for sample in X])\n",
    "\n",
    "    def _predict_sample(self, sample, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "\n",
    "        feature = tree['feature']\n",
    "        threshold = tree['threshold']\n",
    "\n",
    "        if sample[feature] <= threshold:\n",
    "            return self._predict_sample(sample, tree['left'])\n",
    "        else:\n",
    "            return self._predict_sample(sample, tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thPejxUUCBtz",
    "outputId": "f180e23c-5e58-4a17-881a-71f036a045cb"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w8/_c74tplx26q91cmt17qdmvg80000gn/T/ipykernel_22385/1180715228.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;31m# Train and evaluate the custom decision tree with entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtree_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtree_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w8/_c74tplx26q91cmt17qdmvg80000gn/T/ipykernel_22385/3967728902.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, feature_names)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/1-1/ML/FinalProjectML/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'feature_names'"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the custom decision tree with entropy\n",
    "\n",
    "tree_entropy = DecisionTree(max_depth=2, criterion='entropy',min_samples_leaf=5)\n",
    "tree_entropy.fit(X_train, y_train)\n",
    "# Predict on training and testing data\n",
    "y_pred_train_entropy = tree_entropy.predict(X_train)\n",
    "y_pred_test_entropy = tree_entropy.predict(X_test)\n",
    "# Calculate training and testing accuracy\n",
    "accuracy_train_entropy = accuracy_score(y_train, y_pred_train_entropy)\n",
    "accuracy_test_entropy = accuracy_score(y_test, y_pred_test_entropy)\n",
    "# Print training and testing accuracy\n",
    "print(f\"\\nCustom Decision Tree (Entropy) - Training Accuracy: {accuracy_train_entropy:.4f}\")\n",
    "print(f\"Custom Decision Tree (Entropy) - Testing Accuracy: {accuracy_test_entropy:.4f}\")\n",
    "\n",
    "# Train and evaluate the custom decision tree with gini\n",
    "tree_gini = DecisionTree(max_depth=2, criterion='gini',min_samples_leaf=5)\n",
    "tree_gini.fit(X_train, y_train)\n",
    "# Predict on training and testing data\n",
    "y_pred_train_gini = tree_gini.predict(X_train)\n",
    "y_pred_test_gini = tree_gini.predict(X_test)\n",
    "# Calculate training and testing accuracy\n",
    "accuracy_train_gini = accuracy_score(y_train, y_pred_train_gini)\n",
    "accuracy_test_gini = accuracy_score(y_test, y_pred_test_gini)\n",
    "# Print training and testing accuracy\n",
    "print(f\"\\nCustom Decision Tree (Gini) - Training Accuracy: {accuracy_train_gini:.4f}\")\n",
    "print(f\"Custom Decision Tree (Gini) - Testing Accuracy: {accuracy_test_gini:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming X_train and y_train are your training data\n",
    "dt = DecisionTree(max_depth=3)\n",
    "dt.fit(X_train, y_train, feature_names=feature_names)  # Pass feature names\n",
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "n59wSbAwYfMN",
    "outputId": "1e2cca1f-a1af-453c-de0e-3a71105372aa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_train_entropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a dictionary to store the results\u001b[39;00m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 'Model': ['Custom (Entropy)', 'Custom (Gini)', 'sklearn (Entropy)', 'sklearn (Gini)'],\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustom (Entropy)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustom (Gini)\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[43maccuracy_train_entropy\u001b[49m, accuracy_train_gini],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: [accuracy_test_entropy, accuracy_test_gini]\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create a pandas DataFrame from the results dictionary\u001b[39;00m\n\u001b[1;32m     10\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_train_entropy' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {\n",
    "    # 'Model': ['Custom (Entropy)', 'Custom (Gini)', 'sklearn (Entropy)', 'sklearn (Gini)'],\n",
    "    'Model': ['Custom (Entropy)', 'Custom (Gini)'],\n",
    "    'Training Accuracy': [accuracy_train_entropy, accuracy_train_gini],\n",
    "    'Testing Accuracy': [accuracy_test_entropy, accuracy_test_gini]\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame from the results dictionary\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the table\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
